{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ching870423\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>bert_vector_0</th>\n",
       "      <th>bert_vector_1</th>\n",
       "      <th>bert_vector_2</th>\n",
       "      <th>bert_vector_3</th>\n",
       "      <th>bert_vector_4</th>\n",
       "      <th>bert_vector_5</th>\n",
       "      <th>bert_vector_6</th>\n",
       "      <th>bert_vector_7</th>\n",
       "      <th>bert_vector_8</th>\n",
       "      <th>...</th>\n",
       "      <th>bert_vector_758</th>\n",
       "      <th>bert_vector_759</th>\n",
       "      <th>bert_vector_760</th>\n",
       "      <th>bert_vector_761</th>\n",
       "      <th>bert_vector_762</th>\n",
       "      <th>bert_vector_763</th>\n",
       "      <th>bert_vector_764</th>\n",
       "      <th>bert_vector_765</th>\n",
       "      <th>bert_vector_766</th>\n",
       "      <th>bert_vector_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020267472</td>\n",
       "      <td>0.75747156</td>\n",
       "      <td>-0.46656403</td>\n",
       "      <td>-0.11255891</td>\n",
       "      <td>-0.033412203</td>\n",
       "      <td>-1.4196646</td>\n",
       "      <td>0.41839132</td>\n",
       "      <td>-0.7267835</td>\n",
       "      <td>0.055385377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4754434</td>\n",
       "      <td>0.5788282</td>\n",
       "      <td>0.2512459</td>\n",
       "      <td>0.33717856</td>\n",
       "      <td>-0.04361203</td>\n",
       "      <td>0.10473184</td>\n",
       "      <td>0.12372534</td>\n",
       "      <td>0.26182047</td>\n",
       "      <td>-0.15334906</td>\n",
       "      <td>0.2093486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0021113</td>\n",
       "      <td>-0.062211618</td>\n",
       "      <td>-0.23440504</td>\n",
       "      <td>0.080622606</td>\n",
       "      <td>0.2921665</td>\n",
       "      <td>-0.99347395</td>\n",
       "      <td>-0.027160695</td>\n",
       "      <td>0.2217245</td>\n",
       "      <td>-0.12071721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04805429</td>\n",
       "      <td>0.10117429</td>\n",
       "      <td>0.09444845</td>\n",
       "      <td>0.2637279</td>\n",
       "      <td>-0.2169968</td>\n",
       "      <td>0.3337275</td>\n",
       "      <td>0.14923847</td>\n",
       "      <td>0.11658758</td>\n",
       "      <td>-0.23871537</td>\n",
       "      <td>0.3275528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.87568986</td>\n",
       "      <td>0.17762871</td>\n",
       "      <td>-0.27308464</td>\n",
       "      <td>-0.03412449</td>\n",
       "      <td>-0.19497618</td>\n",
       "      <td>-1.38861</td>\n",
       "      <td>0.0671176</td>\n",
       "      <td>-0.07423317</td>\n",
       "      <td>0.049331367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.09813332</td>\n",
       "      <td>-0.21728952</td>\n",
       "      <td>0.40726012</td>\n",
       "      <td>0.45356283</td>\n",
       "      <td>-0.3178441</td>\n",
       "      <td>0.50333756</td>\n",
       "      <td>0.0391796</td>\n",
       "      <td>0.32122022</td>\n",
       "      <td>-0.43077198</td>\n",
       "      <td>0.31658283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.9022963</td>\n",
       "      <td>0.050267387</td>\n",
       "      <td>-0.2953254</td>\n",
       "      <td>0.068135</td>\n",
       "      <td>-0.26593244</td>\n",
       "      <td>-1.1515969</td>\n",
       "      <td>-0.14565651</td>\n",
       "      <td>0.13547245</td>\n",
       "      <td>0.054319736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17675361</td>\n",
       "      <td>-0.10184831</td>\n",
       "      <td>0.0861506</td>\n",
       "      <td>0.08526592</td>\n",
       "      <td>-0.58392036</td>\n",
       "      <td>0.64128655</td>\n",
       "      <td>0.11504253</td>\n",
       "      <td>0.2032882</td>\n",
       "      <td>-0.31452182</td>\n",
       "      <td>0.20748326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0384017</td>\n",
       "      <td>0.034001045</td>\n",
       "      <td>-0.14720243</td>\n",
       "      <td>0.31170148</td>\n",
       "      <td>-0.17978391</td>\n",
       "      <td>-0.9669448</td>\n",
       "      <td>-0.07549889</td>\n",
       "      <td>0.12234016</td>\n",
       "      <td>-0.053179987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14708841</td>\n",
       "      <td>-0.0785914</td>\n",
       "      <td>0.11743203</td>\n",
       "      <td>0.013218408</td>\n",
       "      <td>-0.45160997</td>\n",
       "      <td>0.37011358</td>\n",
       "      <td>0.07652522</td>\n",
       "      <td>0.10110741</td>\n",
       "      <td>-0.4506287</td>\n",
       "      <td>0.26291174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.70624256</td>\n",
       "      <td>-0.12673865</td>\n",
       "      <td>-0.3872698</td>\n",
       "      <td>0.08576806</td>\n",
       "      <td>0.00018439753</td>\n",
       "      <td>-0.91993827</td>\n",
       "      <td>-0.0064524277</td>\n",
       "      <td>-0.09351349</td>\n",
       "      <td>-0.20228474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13829872</td>\n",
       "      <td>0.063795656</td>\n",
       "      <td>-0.12039467</td>\n",
       "      <td>0.19424058</td>\n",
       "      <td>-0.18705708</td>\n",
       "      <td>0.6148556</td>\n",
       "      <td>0.16478638</td>\n",
       "      <td>0.2534663</td>\n",
       "      <td>-0.40866747</td>\n",
       "      <td>0.1909664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.8603882</td>\n",
       "      <td>0.10539106</td>\n",
       "      <td>-0.4210144</td>\n",
       "      <td>-0.07194983</td>\n",
       "      <td>-0.20575444</td>\n",
       "      <td>-1.3835012</td>\n",
       "      <td>0.020379176</td>\n",
       "      <td>0.11768968</td>\n",
       "      <td>-0.104812786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067252874</td>\n",
       "      <td>0.0109966975</td>\n",
       "      <td>-0.20800109</td>\n",
       "      <td>0.046491016</td>\n",
       "      <td>-0.5279493</td>\n",
       "      <td>0.6035681</td>\n",
       "      <td>0.030816687</td>\n",
       "      <td>0.21295957</td>\n",
       "      <td>-0.2918331</td>\n",
       "      <td>0.41778454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>0.8760949</td>\n",
       "      <td>-0.11089752</td>\n",
       "      <td>-0.33412173</td>\n",
       "      <td>0.009016361</td>\n",
       "      <td>-0.21287124</td>\n",
       "      <td>-1.2319462</td>\n",
       "      <td>-0.039061453</td>\n",
       "      <td>0.2166507</td>\n",
       "      <td>-0.13023321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11620769</td>\n",
       "      <td>-0.095250145</td>\n",
       "      <td>-0.06381476</td>\n",
       "      <td>0.18517217</td>\n",
       "      <td>-0.5533239</td>\n",
       "      <td>0.6150509</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.22534223</td>\n",
       "      <td>-0.27210054</td>\n",
       "      <td>0.36950773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.7528038</td>\n",
       "      <td>-0.0820346</td>\n",
       "      <td>-0.3377716</td>\n",
       "      <td>-0.19744256</td>\n",
       "      <td>-0.23435491</td>\n",
       "      <td>-1.4473777</td>\n",
       "      <td>-0.1767919</td>\n",
       "      <td>0.055137035</td>\n",
       "      <td>0.06908232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2032201</td>\n",
       "      <td>0.034207802</td>\n",
       "      <td>-0.006119725</td>\n",
       "      <td>0.17684726</td>\n",
       "      <td>-0.38829416</td>\n",
       "      <td>0.64801246</td>\n",
       "      <td>-0.0016668172</td>\n",
       "      <td>0.35396713</td>\n",
       "      <td>-0.22703923</td>\n",
       "      <td>0.5205603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>0.92797</td>\n",
       "      <td>-0.0062244628</td>\n",
       "      <td>-0.32788402</td>\n",
       "      <td>0.048164286</td>\n",
       "      <td>-0.1404587</td>\n",
       "      <td>-1.1233022</td>\n",
       "      <td>-0.25883695</td>\n",
       "      <td>-0.12796032</td>\n",
       "      <td>-0.058457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15527037</td>\n",
       "      <td>-0.07057593</td>\n",
       "      <td>-0.17064537</td>\n",
       "      <td>0.03451852</td>\n",
       "      <td>-0.50263697</td>\n",
       "      <td>0.4258615</td>\n",
       "      <td>0.20031272</td>\n",
       "      <td>0.07659869</td>\n",
       "      <td>-0.46042386</td>\n",
       "      <td>0.35296193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id bert_vector_0  bert_vector_1 bert_vector_2 bert_vector_3  \\\n",
       "0           1   0.020267472     0.75747156   -0.46656403   -0.11255891   \n",
       "1           4     1.0021113   -0.062211618   -0.23440504   0.080622606   \n",
       "2           5    0.87568986     0.17762871   -0.27308464   -0.03412449   \n",
       "3           6     0.9022963    0.050267387    -0.2953254      0.068135   \n",
       "4           7     1.0384017    0.034001045   -0.14720243    0.31170148   \n",
       "5           8    0.70624256    -0.12673865    -0.3872698    0.08576806   \n",
       "6          13     0.8603882     0.10539106    -0.4210144   -0.07194983   \n",
       "7          14     0.8760949    -0.11089752   -0.33412173   0.009016361   \n",
       "8          15     0.7528038     -0.0820346    -0.3377716   -0.19744256   \n",
       "9          16       0.92797  -0.0062244628   -0.32788402   0.048164286   \n",
       "\n",
       "   bert_vector_4 bert_vector_5  bert_vector_6 bert_vector_7 bert_vector_8  \\\n",
       "0   -0.033412203    -1.4196646     0.41839132    -0.7267835   0.055385377   \n",
       "1      0.2921665   -0.99347395   -0.027160695     0.2217245   -0.12071721   \n",
       "2    -0.19497618      -1.38861      0.0671176   -0.07423317   0.049331367   \n",
       "3    -0.26593244    -1.1515969    -0.14565651    0.13547245   0.054319736   \n",
       "4    -0.17978391    -0.9669448    -0.07549889    0.12234016  -0.053179987   \n",
       "5  0.00018439753   -0.91993827  -0.0064524277   -0.09351349   -0.20228474   \n",
       "6    -0.20575444    -1.3835012    0.020379176    0.11768968  -0.104812786   \n",
       "7    -0.21287124    -1.2319462   -0.039061453     0.2166507   -0.13023321   \n",
       "8    -0.23435491    -1.4473777     -0.1767919   0.055137035    0.06908232   \n",
       "9     -0.1404587    -1.1233022    -0.25883695   -0.12796032     -0.058457   \n",
       "\n",
       "   ... bert_vector_758 bert_vector_759 bert_vector_760 bert_vector_761  \\\n",
       "0  ...       0.4754434       0.5788282       0.2512459      0.33717856   \n",
       "1  ...     -0.04805429      0.10117429      0.09444845       0.2637279   \n",
       "2  ...     -0.09813332     -0.21728952      0.40726012      0.45356283   \n",
       "3  ...     -0.17675361     -0.10184831       0.0861506      0.08526592   \n",
       "4  ...     -0.14708841      -0.0785914      0.11743203     0.013218408   \n",
       "5  ...     -0.13829872     0.063795656     -0.12039467      0.19424058   \n",
       "6  ...    -0.067252874    0.0109966975     -0.20800109     0.046491016   \n",
       "7  ...      0.11620769    -0.095250145     -0.06381476      0.18517217   \n",
       "8  ...      -0.2032201     0.034207802    -0.006119725      0.17684726   \n",
       "9  ...     -0.15527037     -0.07057593     -0.17064537      0.03451852   \n",
       "\n",
       "  bert_vector_762 bert_vector_763 bert_vector_764 bert_vector_765  \\\n",
       "0     -0.04361203      0.10473184      0.12372534      0.26182047   \n",
       "1      -0.2169968       0.3337275      0.14923847      0.11658758   \n",
       "2      -0.3178441      0.50333756       0.0391796      0.32122022   \n",
       "3     -0.58392036      0.64128655      0.11504253       0.2032882   \n",
       "4     -0.45160997      0.37011358      0.07652522      0.10110741   \n",
       "5     -0.18705708       0.6148556      0.16478638       0.2534663   \n",
       "6      -0.5279493       0.6035681     0.030816687      0.21295957   \n",
       "7      -0.5533239       0.6150509        0.229508      0.22534223   \n",
       "8     -0.38829416      0.64801246   -0.0016668172      0.35396713   \n",
       "9     -0.50263697       0.4258615      0.20031272      0.07659869   \n",
       "\n",
       "  bert_vector_766 bert_vector_767  \n",
       "0     -0.15334906       0.2093486  \n",
       "1     -0.23871537       0.3275528  \n",
       "2     -0.43077198      0.31658283  \n",
       "3     -0.31452182      0.20748326  \n",
       "4      -0.4506287      0.26291174  \n",
       "5     -0.40866747       0.1909664  \n",
       "6      -0.2918331      0.41778454  \n",
       "7     -0.27210054      0.36950773  \n",
       "8     -0.22703923       0.5205603  \n",
       "9     -0.46042386      0.35296193  \n",
       "\n",
       "[10 rows x 769 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get input dta and delete the row with '-'\n",
    "bert_df = pd.read_csv('C:/Users/ching870423/nlp_processing/bert_as_server_vector_v2-512.csv')\n",
    "# get names of indexes for which column 'bert_vector_0' has value '-'\n",
    "index_names = bert_df[bert_df['bert_vector_0'] == '-' ].index\n",
    "# drop these row indexes from DataFrame: ad\n",
    "bert_data = bert_df.drop(index_names, inplace = False)\n",
    "bert_data = bert_data.reset_index(drop=True)\n",
    "bert_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "size of X: 90696\n",
      "size of X_train: 45348\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "size of X_test: 45348\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# seperate features from labels and split dataset in train and test data\n",
    "Y = bert_data.iloc[:, 0] # just for split the training & testing data\n",
    "X = bert_data.iloc[:, 1:]\n",
    "#X.head(10)\n",
    "print(type(X))\n",
    "print(\"size of X: {}\".format(len(X)))\n",
    "\n",
    "# split dataset in training and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.5, random_state=0)\n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "print(\"size of X_train: {}\".format(len(X_train)))\n",
    "print(type(X_train))\n",
    "print(\"size of X_test: {}\".format(len(X_test)))\n",
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_num: 768\n",
      "Tensor(\"input_5:0\", shape=(None, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# input information\n",
    "col_num = X.shape[1]\n",
    "print(\"col_num: {}\".format(col_num))\n",
    "input_dim = Input(shape=(col_num,))\n",
    "print(input_dim)\n",
    "\n",
    "# encoding information\n",
    "encoding_dim=28\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_dim)\n",
    "# decoding information\n",
    "decoded = Dense(col_num, activation='sigmoid')(encoded)\n",
    "# autoencoder information (encoder + decoder)\n",
    "autoencoder = Model(inputs=input_dim, outputs=decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "454/454 [==============================] - 3s 6ms/step - loss: 0.4156 - val_loss: 0.4139\n",
      "Epoch 2/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.4119 - val_loss: 0.4102\n",
      "Epoch 3/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.4082 - val_loss: 0.4064\n",
      "Epoch 4/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.4045 - val_loss: 0.4028\n",
      "Epoch 5/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.4009 - val_loss: 0.3993\n",
      "Epoch 6/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3975 - val_loss: 0.3959\n",
      "Epoch 7/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3942 - val_loss: 0.3927\n",
      "Epoch 8/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3911 - val_loss: 0.3897\n",
      "Epoch 9/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3881 - val_loss: 0.3868\n",
      "Epoch 10/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3853 - val_loss: 0.3841\n",
      "Epoch 11/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3827 - val_loss: 0.3815\n",
      "Epoch 12/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3802 - val_loss: 0.3791\n",
      "Epoch 13/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3778 - val_loss: 0.3768\n",
      "Epoch 14/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3756 - val_loss: 0.3746\n",
      "Epoch 15/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3735 - val_loss: 0.3726\n",
      "Epoch 16/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3715 - val_loss: 0.3707\n",
      "Epoch 17/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3697 - val_loss: 0.3689\n",
      "Epoch 18/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3679 - val_loss: 0.3672\n",
      "Epoch 19/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3663 - val_loss: 0.3657\n",
      "Epoch 20/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3648 - val_loss: 0.3642\n",
      "Epoch 21/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3634 - val_loss: 0.3628\n",
      "Epoch 22/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3621 - val_loss: 0.3615\n",
      "Epoch 23/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3608 - val_loss: 0.3603\n",
      "Epoch 24/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3597 - val_loss: 0.3592\n",
      "Epoch 25/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3586 - val_loss: 0.3582\n",
      "Epoch 26/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3576 - val_loss: 0.3572\n",
      "Epoch 27/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3566 - val_loss: 0.3563\n",
      "Epoch 28/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3557 - val_loss: 0.3554\n",
      "Epoch 29/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3549 - val_loss: 0.3546\n",
      "Epoch 30/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3542 - val_loss: 0.3539\n",
      "Epoch 31/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3534 - val_loss: 0.3532\n",
      "Epoch 32/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3528 - val_loss: 0.3525\n",
      "Epoch 33/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3521 - val_loss: 0.3519\n",
      "Epoch 34/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3515 - val_loss: 0.3514\n",
      "Epoch 35/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3510 - val_loss: 0.3508\n",
      "Epoch 36/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3505 - val_loss: 0.3503\n",
      "Epoch 37/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3500 - val_loss: 0.3499\n",
      "Epoch 38/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3495 - val_loss: 0.3494\n",
      "Epoch 39/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3491 - val_loss: 0.3490\n",
      "Epoch 40/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3487 - val_loss: 0.3486\n",
      "Epoch 41/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3483 - val_loss: 0.3482\n",
      "Epoch 42/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3480 - val_loss: 0.3479\n",
      "Epoch 43/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3476 - val_loss: 0.3476\n",
      "Epoch 44/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3473 - val_loss: 0.3473\n",
      "Epoch 45/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3470 - val_loss: 0.3470\n",
      "Epoch 46/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3467 - val_loss: 0.3467\n",
      "Epoch 47/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3465 - val_loss: 0.3464\n",
      "Epoch 48/50\n",
      "454/454 [==============================] - 2s 3ms/step - loss: 0.3462 - val_loss: 0.3462\n",
      "Epoch 49/50\n",
      "454/454 [==============================] - 2s 4ms/step - loss: 0.3460 - val_loss: 0.3460\n",
      "Epoch 50/50\n",
      "454/454 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.3457\n",
      "size of encoded_output: 90696\n",
      "[[ 6.316726    1.7484477   8.595144    6.832994    7.01139     3.7241929\n",
      "   5.3686495   0.          0.          5.7914762   0.          8.616878\n",
      "   0.6866997   0.10852473  0.          0.          0.          0.\n",
      "   0.          5.506609    0.          0.          9.757976    7.9237876\n",
      "   5.2434773   0.          4.3658853   3.215165  ]\n",
      " [ 6.8932633   3.3785641  10.249997    9.802       8.167397    5.694557\n",
      "   7.497062    0.          0.          5.978473    0.         11.633905\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          7.231044    0.          0.         11.744334    8.7198305\n",
      "   6.548387    0.          6.2440476   4.5718045 ]\n",
      " [ 6.8903956   3.462424    9.847597    9.170464    7.9899206   5.905081\n",
      "   6.8078628   0.          0.          6.063156    0.         11.57586\n",
      "   0.04896523  0.          0.          0.          0.          0.\n",
      "   0.          6.6219454   0.          0.         11.477976    8.695734\n",
      "   6.177657    0.          6.032873    4.211898  ]\n",
      " [ 6.8444943   3.5313342  10.139969    9.487513    8.228386    5.858241\n",
      "   7.0390997   0.          0.          6.576522    0.         11.281594\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          7.1473036   0.          0.         11.279841    8.561908\n",
      "   6.2372413   0.          6.1222415   4.402761  ]\n",
      " [ 7.132279    3.7708828   9.810324    9.794638    7.929119    5.743272\n",
      "   7.0268126   0.          0.          6.30721     0.         11.9431505\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          6.925005    0.          0.         11.756431    8.650185\n",
      "   6.533213    0.          6.1999917   4.4513783 ]]\n"
     ]
    }
   ],
   "source": [
    "# train the autoencoder\n",
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=100, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# encoder information for feature extraction\n",
    "encoder = Model(inputs=input_dim, outputs=encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "X = X.astype('float64')\n",
    "encoded_output = encoder.predict(X)\n",
    "\n",
    "#show the encoded values\n",
    "print(\"size of encoded_output: {}\".format(len(encoded_output)))\n",
    "print(encoded_output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_output[0])\n",
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>bert_vector_0</th>\n",
       "      <th>bert_vector_1</th>\n",
       "      <th>bert_vector_2</th>\n",
       "      <th>bert_vector_3</th>\n",
       "      <th>bert_vector_4</th>\n",
       "      <th>bert_vector_5</th>\n",
       "      <th>bert_vector_6</th>\n",
       "      <th>bert_vector_7</th>\n",
       "      <th>bert_vector_8</th>\n",
       "      <th>...</th>\n",
       "      <th>bert_vector_18</th>\n",
       "      <th>bert_vector_19</th>\n",
       "      <th>bert_vector_20</th>\n",
       "      <th>bert_vector_21</th>\n",
       "      <th>bert_vector_22</th>\n",
       "      <th>bert_vector_23</th>\n",
       "      <th>bert_vector_24</th>\n",
       "      <th>bert_vector_25</th>\n",
       "      <th>bert_vector_26</th>\n",
       "      <th>bert_vector_27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.316726</td>\n",
       "      <td>1.748448</td>\n",
       "      <td>8.595144</td>\n",
       "      <td>6.832994</td>\n",
       "      <td>7.011390</td>\n",
       "      <td>3.724193</td>\n",
       "      <td>5.368649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.506609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.757976</td>\n",
       "      <td>7.923788</td>\n",
       "      <td>5.243477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.365885</td>\n",
       "      <td>3.215165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>6.893263</td>\n",
       "      <td>3.378564</td>\n",
       "      <td>10.249997</td>\n",
       "      <td>9.802000</td>\n",
       "      <td>8.167397</td>\n",
       "      <td>5.694557</td>\n",
       "      <td>7.497062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.231044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.744334</td>\n",
       "      <td>8.719831</td>\n",
       "      <td>6.548387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.244048</td>\n",
       "      <td>4.571805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6.890396</td>\n",
       "      <td>3.462424</td>\n",
       "      <td>9.847597</td>\n",
       "      <td>9.170464</td>\n",
       "      <td>7.989921</td>\n",
       "      <td>5.905081</td>\n",
       "      <td>6.807863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.621945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.477976</td>\n",
       "      <td>8.695734</td>\n",
       "      <td>6.177657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032873</td>\n",
       "      <td>4.211898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6.844494</td>\n",
       "      <td>3.531334</td>\n",
       "      <td>10.139969</td>\n",
       "      <td>9.487513</td>\n",
       "      <td>8.228386</td>\n",
       "      <td>5.858241</td>\n",
       "      <td>7.039100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.147304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.279841</td>\n",
       "      <td>8.561908</td>\n",
       "      <td>6.237241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.122241</td>\n",
       "      <td>4.402761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7.132279</td>\n",
       "      <td>3.770883</td>\n",
       "      <td>9.810324</td>\n",
       "      <td>9.794638</td>\n",
       "      <td>7.929119</td>\n",
       "      <td>5.743272</td>\n",
       "      <td>7.026813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.925005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.756431</td>\n",
       "      <td>8.650185</td>\n",
       "      <td>6.533213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.199992</td>\n",
       "      <td>4.451378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>6.999755</td>\n",
       "      <td>3.746512</td>\n",
       "      <td>9.953068</td>\n",
       "      <td>9.307332</td>\n",
       "      <td>8.140241</td>\n",
       "      <td>5.478404</td>\n",
       "      <td>7.017488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.006401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.575898</td>\n",
       "      <td>8.239146</td>\n",
       "      <td>6.330299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.998165</td>\n",
       "      <td>4.405717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>6.742296</td>\n",
       "      <td>3.896115</td>\n",
       "      <td>10.098818</td>\n",
       "      <td>9.391274</td>\n",
       "      <td>8.211959</td>\n",
       "      <td>6.137934</td>\n",
       "      <td>6.917583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.119794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.566936</td>\n",
       "      <td>8.627813</td>\n",
       "      <td>6.285488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.291746</td>\n",
       "      <td>4.903709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>6.999968</td>\n",
       "      <td>3.862267</td>\n",
       "      <td>10.518359</td>\n",
       "      <td>9.539685</td>\n",
       "      <td>8.712132</td>\n",
       "      <td>6.294590</td>\n",
       "      <td>7.076313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.426547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.963862</td>\n",
       "      <td>8.976734</td>\n",
       "      <td>6.373786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208028</td>\n",
       "      <td>4.690140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>7.154242</td>\n",
       "      <td>3.724764</td>\n",
       "      <td>10.260337</td>\n",
       "      <td>9.278212</td>\n",
       "      <td>8.267303</td>\n",
       "      <td>5.993077</td>\n",
       "      <td>7.133318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.058702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.657099</td>\n",
       "      <td>8.558410</td>\n",
       "      <td>6.144103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.937777</td>\n",
       "      <td>4.759901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>6.750030</td>\n",
       "      <td>3.768084</td>\n",
       "      <td>10.428137</td>\n",
       "      <td>9.602785</td>\n",
       "      <td>8.108593</td>\n",
       "      <td>5.743488</td>\n",
       "      <td>7.020402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.080482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.273370</td>\n",
       "      <td>8.596780</td>\n",
       "      <td>6.453251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.952003</td>\n",
       "      <td>4.616378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  bert_vector_0  bert_vector_1  bert_vector_2  bert_vector_3  \\\n",
       "0           1       6.316726       1.748448       8.595144       6.832994   \n",
       "1           4       6.893263       3.378564      10.249997       9.802000   \n",
       "2           5       6.890396       3.462424       9.847597       9.170464   \n",
       "3           6       6.844494       3.531334      10.139969       9.487513   \n",
       "4           7       7.132279       3.770883       9.810324       9.794638   \n",
       "5           8       6.999755       3.746512       9.953068       9.307332   \n",
       "6          13       6.742296       3.896115      10.098818       9.391274   \n",
       "7          14       6.999968       3.862267      10.518359       9.539685   \n",
       "8          15       7.154242       3.724764      10.260337       9.278212   \n",
       "9          16       6.750030       3.768084      10.428137       9.602785   \n",
       "\n",
       "   bert_vector_4  bert_vector_5  bert_vector_6  bert_vector_7  bert_vector_8  \\\n",
       "0       7.011390       3.724193       5.368649            0.0            0.0   \n",
       "1       8.167397       5.694557       7.497062            0.0            0.0   \n",
       "2       7.989921       5.905081       6.807863            0.0            0.0   \n",
       "3       8.228386       5.858241       7.039100            0.0            0.0   \n",
       "4       7.929119       5.743272       7.026813            0.0            0.0   \n",
       "5       8.140241       5.478404       7.017488            0.0            0.0   \n",
       "6       8.211959       6.137934       6.917583            0.0            0.0   \n",
       "7       8.712132       6.294590       7.076313            0.0            0.0   \n",
       "8       8.267303       5.993077       7.133318            0.0            0.0   \n",
       "9       8.108593       5.743488       7.020402            0.0            0.0   \n",
       "\n",
       "   ...  bert_vector_18  bert_vector_19  bert_vector_20  bert_vector_21  \\\n",
       "0  ...             0.0        5.506609             0.0             0.0   \n",
       "1  ...             0.0        7.231044             0.0             0.0   \n",
       "2  ...             0.0        6.621945             0.0             0.0   \n",
       "3  ...             0.0        7.147304             0.0             0.0   \n",
       "4  ...             0.0        6.925005             0.0             0.0   \n",
       "5  ...             0.0        7.006401             0.0             0.0   \n",
       "6  ...             0.0        7.119794             0.0             0.0   \n",
       "7  ...             0.0        7.426547             0.0             0.0   \n",
       "8  ...             0.0        7.058702             0.0             0.0   \n",
       "9  ...             0.0        7.080482             0.0             0.0   \n",
       "\n",
       "   bert_vector_22  bert_vector_23  bert_vector_24  bert_vector_25  \\\n",
       "0        9.757976        7.923788        5.243477             0.0   \n",
       "1       11.744334        8.719831        6.548387             0.0   \n",
       "2       11.477976        8.695734        6.177657             0.0   \n",
       "3       11.279841        8.561908        6.237241             0.0   \n",
       "4       11.756431        8.650185        6.533213             0.0   \n",
       "5       11.575898        8.239146        6.330299             0.0   \n",
       "6       11.566936        8.627813        6.285488             0.0   \n",
       "7       11.963862        8.976734        6.373786             0.0   \n",
       "8       11.657099        8.558410        6.144103             0.0   \n",
       "9       11.273370        8.596780        6.453251             0.0   \n",
       "\n",
       "   bert_vector_26  bert_vector_27  \n",
       "0        4.365885        3.215165  \n",
       "1        6.244048        4.571805  \n",
       "2        6.032873        4.211898  \n",
       "3        6.122241        4.402761  \n",
       "4        6.199992        4.451378  \n",
       "5        5.998165        4.405717  \n",
       "6        6.291746        4.903709  \n",
       "7        6.208028        4.690140  \n",
       "8        5.937777        4.759901  \n",
       "9        5.952003        4.616378  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output as a csv file\n",
    "cols_name = []\n",
    "for i in range(len(encoded_output[0])):\n",
    "    cols_name.append('bert_vector_{}'.format(i))\n",
    "bert_28 = pd.DataFrame(encoded_output, columns=cols_name)\n",
    "bert_28.insert(0, 'article_id', Y)\n",
    "file_name = 'bert_autoencoder_512_to_28.csv'\n",
    "bert_28.to_csv(file_name, index=False)\n",
    "bert_28.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
